#!/usr/bin/env python3
"""
æœ€å°åŒ–LM Studioæµ‹è¯•ï¼ˆæ— å¤–éƒ¨ä¾èµ–ï¼‰
"""

import subprocess
import json
import sys
from pathlib import Path

def test_with_curl():
    """ä½¿ç”¨curlæµ‹è¯•LM Studio"""
    print("ğŸ§ª ä½¿ç”¨curlæµ‹è¯•LM Studio")
    print("=" * 40)

    model_name = "openai/gpt-oss-20b"

    # 1. æµ‹è¯•æ¨¡å‹åˆ—è¡¨
    print("\n1. æµ‹è¯•æ¨¡å‹åˆ—è¡¨...")
    try:
        result = subprocess.run([
            'curl', '-s', '--connect-timeout', '5',
            'http://127.0.0.1:1234/v1/models'
        ], capture_output=True, text=True, timeout=10)

        if result.returncode == 0:
            data = json.loads(result.stdout)
            models = data.get('data', [])
            print(f"âœ… è¿æ¥æˆåŠŸï¼å‘ç° {len(models)} ä¸ªæ¨¡å‹")

            # æŸ¥æ‰¾ç›®æ ‡æ¨¡å‹
            model_found = False
            for model in models:
                model_id = model.get('id', '')
                if model_id == model_name:
                    model_found = True
                    print(f"âœ… æ‰¾åˆ°ç›®æ ‡æ¨¡å‹: {model_name}")
                    break

            if not model_found:
                print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹: {model_name}")
                print("å¯ç”¨æ¨¡å‹:")
                for model in models[:5]:
                    print(f"  â€¢ {model.get('id', 'Unknown')}")
                return False
        else:
            print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {result.stderr}")
            return False

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        return False

    # 2. æµ‹è¯•èŠå¤©è¯·æ±‚
    print(f"\n2. æµ‹è¯•èŠå¤©è¯·æ±‚...")
    try:
        payload = {
            "model": model_name,
            "messages": [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•å›å¤ç¡®è®¤è¿æ¥æ­£å¸¸"}
            ],
            "temperature": 0.3,
            "max_tokens": 50
        }

        payload_str = json.dumps(payload)

        result = subprocess.run([
            'curl', '-s', '-X', 'POST',
            'http://127.0.0.1:1234/v1/chat/completions',
            '-H', 'Content-Type: application/json',
            '-d', payload_str
        ], capture_output=True, text=True, timeout=15)

        if result.returncode == 0:
            response = json.loads(result.stdout)
            content = response.get('choices', [{}])[0].get('message', {}).get('content', '')

            if content:
                print(f"âœ… èŠå¤©æµ‹è¯•æˆåŠŸï¼")
                print(f"  å“åº”: {content}")
                return True
            else:
                print("âŒ å“åº”å†…å®¹ä¸ºç©º")
                print(f"å®Œæ•´å“åº”: {result.stdout}")
                return False
        else:
            print(f"âŒ èŠå¤©è¯·æ±‚å¤±è´¥: {result.stderr}")
            return False

    except Exception as e:
        print(f"âŒ èŠå¤©æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def check_config_file():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
    print("\n" + "=" * 40)
    print("ğŸ“‹ æ£€æŸ¥é…ç½®æ–‡ä»¶")
    print("=" * 40)

    config_file = Path("config/ai_config.yaml")
    if config_file.exists():
        print(f"âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {config_file}")

        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # æ£€æŸ¥å…³é”®é…ç½®
            if "lm_studio:" in content:
                print("âœ… LM Studioé…ç½®å­˜åœ¨")

            if "model_mapping:" in content:
                print("âœ… æ¨¡å‹æ˜ å°„é…ç½®å­˜åœ¨")

            if "openai/gpt-oss-20b" in content:
                print("âœ… æ‰¾åˆ°æ¨¡å‹åç§°é…ç½®")

            # æ£€æŸ¥ç«¯å£é…ç½®
            if "port: 1234" in content:
                print("âœ… ç«¯å£é…ç½®æ­£ç¡®")

            return True

        except Exception as e:
            print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False
    else:
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æœ€å°åŒ–LM Studioæµ‹è¯•")
    print("=" * 50)

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_ok = check_config_file()

    # æµ‹è¯•LM Studioè¿æ¥
    lm_studio_ok = test_with_curl()

    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"  é…ç½®æ–‡ä»¶: {'âœ… æ­£å¸¸' if config_ok else 'âŒ æœ‰é—®é¢˜'}")
    print(f"  LM Studioè¿æ¥: {'âœ… æ­£å¸¸' if lm_studio_ok else 'âŒ æœ‰é—®é¢˜'}")

    if config_ok and lm_studio_ok:
        print("\nğŸ‰ åŸºç¡€æµ‹è¯•é€šè¿‡ï¼")
        print("LM Studio APIå·¥ä½œæ­£å¸¸ï¼Œé—®é¢˜å¯èƒ½åœ¨äº:")
        print("  â€¢ GUIä¸­çš„ä¾èµ–æ¨¡å—ç¼ºå¤±")
        print("  â€¢ é…ç½®ç®¡ç†å™¨å®ç°é—®é¢˜")
        print("  â€¢ è¿æ¥å™¨é…ç½®é—®é¢˜")

        print("\nğŸ’¡ å»ºè®®å®‰è£…ç¼ºå¤±çš„ä¾èµ–:")
        print("  pip install pyyaml requests aiohttp")

    elif lm_studio_ok:
        print("\nâš ï¸ LM Studioå·¥ä½œæ­£å¸¸ï¼Œä½†é…ç½®æ–‡ä»¶æœ‰é—®é¢˜")

    else:
        print("\nâŒ LM Studioè¿æ¥æœ‰é—®é¢˜")
        print("è¯·ç¡®ä¿:")
        print("  â€¢ LM Studioæ­£åœ¨è¿è¡Œ")
        print("  â€¢ æœ¬åœ°æœåŠ¡å™¨å·²å¯åŠ¨ (ç«¯å£1234)")
        print("  â€¢ æ¨¡å‹å·²åŠ è½½å®Œæˆ")

if __name__ == "__main__":
    main()