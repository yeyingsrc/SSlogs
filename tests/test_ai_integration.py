#!/usr/bin/env python3
"""
AIé›†æˆåŠŸèƒ½æµ‹è¯•ç”¨ä¾‹
éªŒè¯LM Studioæ¨¡å‹è¿æ¥å’ŒAIåˆ†æåŠŸèƒ½
"""

import json
import logging
import time
import asyncio
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
import sys
sys.path.append(str(Path(__file__).parent.parent))

from core.rule_engine import RuleEngine
from core.lm_studio_connector import LMStudioConnector, LMStudioConfig
from core.ai_threat_analyzer import AIThreatAnalyzer, get_ai_threat_analyzer, reset_ai_threat_analyzer
from core.intelligent_log_analyzer import IntelligentLogAnalyzer
from core.natural_language_interface import NaturalLanguageInterface
from core.ai_config_manager import get_ai_config_manager

class AIIntegrationTester:
    """AIé›†æˆæµ‹è¯•å™¨"""

    def __init__(self):
        self.logger = self._setup_logging()
        self.test_results = []
        self.rule_engine = None
        self.ai_analyzer = None
        self.intelligent_analyzer = None
        self.nli_interface = None

    def _setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('tests/test_ai_integration.log')
            ]
        )
        return logging.getLogger(__name__)

    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰AIé›†æˆæµ‹è¯•"""
        self.logger.info("ğŸš€ å¼€å§‹AIé›†æˆåŠŸèƒ½æµ‹è¯•...")

        test_results = {
            "lm_studio_connection": self.test_lm_studio_connection(),
            "ai_analyzer": self.test_ai_analyzer(),
            "intelligent_analyzer": self.test_intelligent_analyzer(),
            "natural_language_interface": self.test_natural_language_interface(),
            "end_to_end_integration": self.test_end_to_end_integration(),
            "performance": self.test_performance(),
            "error_handling": self.test_error_handling()
        }

        # æ±‡æ€»æµ‹è¯•ç»“æœ
        total_tests = len(test_results)
        passed_tests = sum(1 for result in test_results.values() if result.get('success', False))
        failed_tests = total_tests - passed_tests

        summary = {
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "failed_tests": failed_tests,
            "success_rate": (passed_tests / total_tests) * 100 if total_tests > 0 else 0,
            "test_results": test_results,
            "timestamp": time.time()
        }

        self.logger.info(f"âœ… AIé›†æˆæµ‹è¯•å®Œæˆ")
        self.logger.info(f"æ€»æµ‹è¯•æ•°: {total_tests}, é€šè¿‡: {passed_tests}, å¤±è´¥: {failed_tests}")
        self.logger.info(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")

        return summary

    def test_lm_studio_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•LM Studioè¿æ¥"""
        self.logger.info("ğŸ”Œ æµ‹è¯•LM Studioè¿æ¥...")

        try:
            # æµ‹è¯•åŸºæœ¬è¿æ¥
            config = LMStudioConfig()
            connector = LMStudioConnector(config)

            connection_test = connector.test_connection()

            if not connection_test:
                return {
                    "success": False,
                    "error": "æ— æ³•è¿æ¥åˆ°LM Studio",
                    "details": "è¯·ç¡®ä¿LM Studioæ­£åœ¨è¿è¡Œå¹¶ç›‘å¬ http://127.0.0.1:1234"
                }

            # æµ‹è¯•æ¨¡å‹åˆ—è¡¨
            available_models = connector.get_available_models()

            # æµ‹è¯•èŠå¤©åŠŸèƒ½
            test_messages = [
                ("system", "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚"),
                ("user", "è¯·å›å¤'è¿æ¥æµ‹è¯•æˆåŠŸ'")
            ]

            from core.lm_studio_connector import ChatMessage
            chat_messages = [ChatMessage(role=role, content=content) for role, content in test_messages]

            chat_response = connector.chat_completion(chat_messages)

            result = {
                "success": True,
                "available_models": available_models,
                "chat_response": chat_response,
                "model_info": connector.get_model_info(),
                "details": f"æˆåŠŸè¿æ¥ï¼Œå‘ç° {len(available_models)} ä¸ªæ¨¡å‹"
            }

            self.logger.info(f"âœ… LM Studioè¿æ¥æµ‹è¯•æˆåŠŸ: {result['details']}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ LM Studioè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "details": "è¿æ¥LM Studioæ—¶å‘ç”Ÿå¼‚å¸¸"
            }

    def test_ai_analyzer(self) -> Dict[str, Any]:
        """æµ‹è¯•AIå¨èƒåˆ†æå™¨"""
        self.logger.info("ğŸ§  æµ‹è¯•AIå¨èƒåˆ†æå™¨...")

        try:
            # é‡ç½®å…¨å±€åˆ†æå™¨å®ä¾‹
            reset_ai_threat_analyzer()

            # åˆ›å»ºAIåˆ†æå™¨
            ai_analyzer = get_ai_threat_analyzer()

            # æ£€æŸ¥è¿æ¥çŠ¶æ€
            status = ai_analyzer.get_analyzer_status()

            if not status['connector_status']['connected']:
                return {
                    "success": False,
                    "error": "AIåˆ†æå™¨æ— æ³•è¿æ¥åˆ°LM Studio",
                    "details": status
                }

            # æµ‹è¯•æ—¥å¿—åˆ†æ
            test_log = {
                "timestamp": "2024-01-15T10:30:00+08:00",
                "src_ip": "192.168.1.100",
                "request_path": "/admin/login?user=admin&pass=123",
                "request_method": "POST",
                "user_agent": "Mozilla/5.0 (compatible; scanner/1.0)",
                "request_body": '{"username": "admin", "password": "123456"}',
                "status_code": "200"
            }

            analysis_result = ai_analyzer.analyze_log_entry(test_log)

            if not analysis_result:
                return {
                    "success": False,
                    "error": "AIåˆ†æè¿”å›ç©ºç»“æœ",
                    "details": "åˆ†æå™¨å¯èƒ½æ— æ³•æ­£å¸¸å¤„ç†è¯·æ±‚"
                }

            # éªŒè¯åˆ†æç»“æœ
            required_fields = ['is_malicious', 'threat_analysis', 'raw_analysis']
            missing_fields = [field for field in required_fields if not hasattr(analysis_result, field)]

            if missing_fields:
                return {
                    "success": False,
                    "error": f"åˆ†æç»“æœç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}",
                    "details": f"åˆ†æå™¨è¿”å›çš„æ•°æ®ç»“æ„ä¸å®Œæ•´"
                }

            result = {
                "success": True,
                "analysis_result": {
                    "is_malicious": analysis_result.is_malicious,
                    "threat_level": analysis_result.threat_analysis.threat_level,
                    "confidence": analysis_result.confidence_score,
                    "attack_types": analysis_result.threat_analysis.attack_types,
                    "processing_time": analysis_result.processing_time,
                    "model_used": analysis_result.model_used
                },
                "analyzer_status": status,
                "details": f"AIåˆ†ææˆåŠŸï¼Œå¨èƒç­‰çº§: {analysis_result.threat_analysis.threat_level}"
            }

            self.logger.info(f"âœ… AIå¨èƒåˆ†æå™¨æµ‹è¯•æˆåŠŸ: {result['details']}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ AIå¨èƒåˆ†æå™¨æµ‹è¯•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "details": "AIåˆ†æå™¨æµ‹è¯•æ—¶å‘ç”Ÿå¼‚å¸¸"
            }

    def test_intelligent_analyzer(self) -> Dict[str, Any]:
        """æµ‹è¯•æ™ºèƒ½æ—¥å¿—åˆ†æå™¨"""
        self.logger.info("ğŸ§  æµ‹è¯•æ™ºèƒ½æ—¥å¿—åˆ†æå™¨...")

        try:
            # åˆ›å»ºè§„åˆ™å¼•æ“
            rule_engine = RuleEngine("rules", enable_ai_analysis=False)

            # åˆ›å»ºAIåˆ†æå™¨
            ai_analyzer = get_ai_threat_analyzer()

            # åˆ›å»ºæ™ºèƒ½åˆ†æå™¨
            intelligent_analyzer = IntelligentLogAnalyzer(rule_engine, ai_analyzer)

            # æµ‹è¯•æ—¥å¿—æ¡ç›®
            test_logs = [
                {
                    "timestamp": "2024-01-15T10:30:00+08:00",
                    "src_ip": "192.168.1.100",
                    "request_path": "/api/users",
                    "request_method": "GET",
                    "user_agent": "Mozilla/5.0 (compatible; scanner/1.0)",
                    "status_code": "200"
                },
                {
                    "timestamp": "2024-01-15T10:31:00+08:00",
                    "src_ip": "185.220.101.182",
                    "request_path": "/admin/login",
                    "request_method": "POST",
                    "user_agent": "sqlmap/1.6.12",
                    "request_body": "username=admin' OR '1'='1&password=test",
                    "status_code": "200"
                }
            ]

            # æµ‹è¯•å•ä¸ªæ—¥å¿—åˆ†æ
            start_time = time.time()
            analysis_results = []

            for log in test_logs:
                result = intelligent_analyzer.analyze_log(log)
                analysis_results.append(result)

            total_time = time.time() - start_time
            avg_time = total_time / len(test_logs)

            # éªŒè¯ç»“æœ
            successful_analyses = sum(1 for r in analysis_results if r.final_threat_score > 0)

            result = {
                "success": True,
                "analysis_count": len(analysis_results),
                "successful_analyses": successful_analyses,
                "total_processing_time": total_time,
                "avg_processing_time": avg_time,
                "high_risk_count": sum(1 for r in analysis_results if r.final_threat_score >= 6.0),
                "analyzer_status": intelligent_analyzer.get_analysis_status(),
                "details": f"æˆåŠŸåˆ†æ {len(test_logs)} æ¡æ—¥å¿—ï¼Œå¹³å‡è€—æ—¶ {avg_time:.3f}s"
            }

            self.logger.info(f"âœ… æ™ºèƒ½æ—¥å¿—åˆ†æå™¨æµ‹è¯•æˆåŠŸ: {result['details']}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ æ™ºèƒ½æ—¥å¿—åˆ†æå™¨æµ‹è¯•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "details": "æ™ºèƒ½åˆ†æå™¨æµ‹è¯•æ—¶å‘ç”Ÿå¼‚å¸¸"
            }

    def test_natural_language_interface(self) -> Dict[str, Any]:
        """æµ‹è¯•è‡ªç„¶è¯­è¨€æ¥å£"""
        self.logger.info("ğŸ’¬ æµ‹è¯•è‡ªç„¶è¯­è¨€æ¥å£...")

        try:
            # åˆ›å»ºåŸºç¡€ç»„ä»¶
            rule_engine = RuleEngine("rules", enable_ai_analysis=False)
            ai_analyzer = get_ai_threat_analyzer()
            intelligent_analyzer = IntelligentLogAnalyzer(rule_engine, ai_analyzer)

            # åˆ›å»ºè‡ªç„¶è¯­è¨€æ¥å£
            nli = NaturalLanguageInterface(intelligent_analyzer)

            # æµ‹è¯•æŸ¥è¯¢
            test_queries = [
                "æœ€è¿‘æœ‰ä»€ä¹ˆå¨èƒäº‹ä»¶ï¼Ÿ",
                "åˆ†æIPåœ°å€ 192.168.1.100",
                "ç³»ç»Ÿæ€§èƒ½æ€ä¹ˆæ ·ï¼Ÿ",
                "æœ‰ä»€ä¹ˆå®‰å…¨å»ºè®®ï¼Ÿ"
            ]

            query_results = []

            for query in test_queries:
                start_time = time.time()
                result = nli.process_query(query)
                processing_time = time.time() - start_time

                query_results.append({
                    "query": query,
                    "intent": result.intent.intent_type,
                    "processing_time": processing_time,
                    "has_answer": bool(result.answer),
                    "answer_length": len(result.answer) if result.answer else 0
                })

            # éªŒè¯ç»“æœ
            successful_queries = sum(1 for q in query_results if q['has_answer'])
            avg_processing_time = sum(q['processing_time'] for q in query_results) / len(query_results)

            result = {
                "success": True,
                "query_count": len(test_queries),
                "successful_queries": successful_queries,
                "avg_processing_time": avg_processing_time,
                "query_results": [
                    {
                        "query": q["query"],
                        "intent": q["intent"],
                        "processing_time": q["processing_time"],
                        "success": q["has_answer"]
                    }
                    for q in query_results
                ],
                "details": f"æˆåŠŸå¤„ç† {successful_queries}/{len(test_queries)} ä¸ªæŸ¥è¯¢ï¼Œå¹³å‡è€—æ—¶ {avg_processing_time:.3f}s"
            }

            self.logger.info(f"âœ… è‡ªç„¶è¯­è¨€æ¥å£æµ‹è¯•æˆåŠŸ: {result['details']}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ è‡ªç„¶è¯­è¨€æ¥å£æµ‹è¯•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "details": "è‡ªç„¶è¯­è¨€æ¥å£æµ‹è¯•æ—¶å‘ç”Ÿå¼‚å¸¸"
            }

    def test_end_to_end_integration(self) -> Dict[str, Any]:
        """æµ‹è¯•ç«¯åˆ°ç«¯é›†æˆ"""
        self.logger.info("ğŸ”„ æµ‹è¯•ç«¯åˆ°ç«¯é›†æˆ...")

        try:
            # åˆ›å»ºå®Œæ•´çš„åˆ†ææµæ°´çº¿
            rule_engine = RuleEngine("rules", enable_ai_analysis=True)
            ai_analyzer = get_ai_threat_analyzer()
            intelligent_analyzer = IntelligentLogAnalyzer(rule_engine, ai_analyzer)

            # æµ‹è¯•å¤æ‚çš„æ”»å‡»åœºæ™¯
            attack_scenarios = [
                {
                    "name": "SQLæ³¨å…¥æ”»å‡»",
                    "log": {
                        "timestamp": "2024-01-15T10:30:00+08:00",
                        "src_ip": "192.168.1.100",
                        "request_path": "/api/users?id=1' OR '1'='1",
                        "request_method": "GET",
                        "user_agent": "Mozilla/5.0",
                        "status_code": "200"
                    }
                },
                {
                    "name": "å‘½ä»¤æ³¨å…¥æ”»å‡»",
                    "log": {
                        "timestamp": "2024-01-15T10:31:00+08:00",
                        "src_ip": "192.168.1.101",
                        "request_path": "/api/system",
                        "request_method": "POST",
                        "request_body": "command=ls -la",
                        "user_agent": "curl/7.68.0",
                        "status_code": "200"
                    }
                },
                {
                    "name": "æ–‡ä»¶ä¸Šä¼ æ”»å‡»",
                    "log": {
                        "timestamp": "2024-01-15T10:32:00+08:00",
                        "src_ip": "192.168.1.102",
                        "request_path": "/upload/file.php",
                        "request_method": "POST",
                        "request_headers": {
                            "Content-Type": "multipart/form-data"
                        },
                        "request_body": "file=<?php system($_GET['cmd']); ?>&name=shell.php",
                        "status_code": "200"
                    }
                }
            ]

            # ä½¿ç”¨AIå¢å¼ºçš„è§„åˆ™å¼•æ“è¿›è¡Œåˆ†æ
            enhanced_results = []

            for scenario in attack_scenarios:
                start_time = time.time()

                # ä½¿ç”¨AIå¢å¼ºåŒ¹é…
                matches = rule_engine.match_log_with_ai(scenario["log"])

                processing_time = time.time() - start_time

                # éªŒè¯AIå¢å¼ºæ•ˆæœ
                has_ai_analysis = any('ai_analysis' in match for match in matches)
                ai_enhanced_matches = [match for match in matches if match.get('ai_analysis')]

                enhanced_results.append({
                    "scenario": scenario["name"],
                    "traditional_matches": len(matches),
                    "ai_enhanced_matches": len(ai_enhanced_matches),
                    "has_ai_analysis": has_ai_analysis,
                    "processing_time": processing_time,
                    "max_threat_score": max([match['threat_score'].score for match in matches]) if matches else 0.0
                })

            # éªŒè¯é›†æˆæ•ˆæœ
            total_enhanced = sum(r['ai_enhanced_matches'] for r in enhanced_results)

            result = {
                "success": True,
                "scenario_count": len(attack_scenarios),
                "enhanced_results": enhanced_results,
                "total_ai_enhancements": total_enhanced,
                "avg_processing_time": sum(r['processing_time'] for r in enhanced_results) / len(enhanced_results),
                "details": f"æˆåŠŸå¢å¼º {total_enhanced}/{len(attack_scenarios)} ä¸ªæ”»å‡»æ£€æµ‹"
            }

            self.logger.info(f"âœ… ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•æˆåŠŸ: {result['details']}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "details": "ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•æ—¶å‘ç”Ÿå¼‚å¸¸"
            }

    def test_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•æ€§èƒ½"""
        self.logger.info("âš¡ æµ‹è¯•AIåŠŸèƒ½æ€§èƒ½...")

        try:
            # åˆ›å»ºåˆ†æå™¨
            rule_engine = RuleEngine("rules", enable_ai_analysis=True)
            intelligent_analyzer = IntelligentLogAnalyzer(rule_engine)

            # æ€§èƒ½æµ‹è¯•å‚æ•°
            batch_sizes = [1, 5, 10, 20]
            performance_results = []

            for batch_size in batch_sizes:
                # ç”Ÿæˆæµ‹è¯•æ—¥å¿—
                test_logs = []
                for i in range(batch_size):
                    test_logs.append({
                        "timestamp": f"2024-01-15T10:{30+i:02d}+08:00",
                        "src_ip": f"192.168.1.{100+i}",
                        "request_path": f"/api/test/{i}",
                        "request_method": "GET",
                        "user_agent": f"TestAgent/{i}",
                        "status_code": "200"
                    })

                # æµ‹è¯•æ‰¹é‡åˆ†ææ€§èƒ½
                start_time = time.time()
                batch_result = intelligent_analyzer.analyze_batch(test_logs)
                processing_time = time.time() - start_time

                throughput = batch_size / processing_time
                avg_time = processing_time / batch_size

                performance_results.append({
                    "batch_size": batch_size,
                    "total_time": processing_time,
                    "avg_time": avg_time,
                    "throughput": throughput,
                    "success_rate": batch_result.successful_analyses / batch_size * 100
                })

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            max_throughput = max(r['throughput'] for r in performance_results)
            min_avg_time = min(r['avg_time'] for r in performance_results)

            result = {
                "success": True,
                "performance_results": performance_results,
                "max_throughput": max_throughput,
                "min_avg_time": min_avg_time,
                "details": f"æœ€å¤§ååé‡: {max_throughput:.1f} æ—¥å¿—/ç§’ï¼Œæœ€å°å¹³å‡è€—æ—¶: {min_avg_time:.3f} ç§’"
            }

            self.logger.info(f"âœ… æ€§èƒ½æµ‹è¯•æˆåŠŸ: {result['details']}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "details": "æ€§èƒ½æµ‹è¯•æ—¶å‘ç”Ÿå¼‚å¸¸"
            }

    def test_error_handling(self) -> Dict[str, Any]:
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        self.pylogger.info("ğŸ›¡ï¸ æµ‹è¯•é”™è¯¯å¤„ç†...")

        try:
            error_test_results = []

            # æµ‹è¯•1: æ— æ•ˆLM Studioè¿æ¥
            try:
                invalid_config = LMStudioConfig(port=9999)
                invalid_connector = LMStudioConnector(invalid_config)
                invalid_connector.test_connection()
                error_test_results.append({
                    "test": "invalid_lm_studio_connection",
                    "success": False,
                    "expected_error": True
                })
            except:
                error_test_results.append({
                    "test": "invalid_lm_studio_connection",
                    "success": True,
                    "expected_error": True
                })

            # æµ‹è¯•2: æ— æ•ˆæ—¥å¿—æ•°æ®
            try:
                invalid_log = {"invalid": "data"}
                ai_analyzer = get_ai_threat_analyzer()
                result = ai_analyzer.analyze_log_entry(invalid_log)

                # åº”è¯¥èƒ½å¤„ç†æ— æ•ˆæ•°æ®è€Œä¸å´©æºƒ
                error_test_results.append({
                    "test": "invalid_log_data",
                    "success": True,
                    "expected_error": False,
                    "handled_gracefully": result is not None
                })
            except Exception as e:
                error_test_results.append({
                    "test": "invalid_log_data",
                    "success": False,
                    "expected_error": False,
                    "error": str(e)
                })

            # æµ‹è¯•3: ç½‘ç»œè¶…æ—¶
            try:
                timeout_config = LMStudioConfig(timeout=0.001)
                timeout_connector = LMStudioConnector(timeout_config)
                timeout_connector.test_connection()
                error_test_results.append({
                    "test": "network_timeout",
                    "success": False,
                    "expected_error": True
                })
            except:
                error_test_results.append({
                    "test": "network_timeout",
                    "success": True,
                    "expected_error": True
                })

            # ç»Ÿè®¡é”™è¯¯å¤„ç†ç»“æœ
            handled_gracefully = sum(1 for r in error_test_results if r['success'] and r.get('expected_error', False))
            expected_errors_handled = sum(1 for r in error_test_results if r['success'] and r.get('expected_error', True))

            result = {
                "success": True,
                "error_tests": error_test_results,
                "handled_gracefully": handled_gracefully,
                "expected_errors_handled": expected_errors_handled,
                "total_tests": len(error_test_results),
                "details": f"ä¼˜é›…å¤„ç†: {handled_gracefully}, æ­£ç¡®å¤„ç†é¢„æœŸé”™è¯¯: {expected_errors_handled}"
            }

            self.logger.info(f"âœ… é”™è¯¯å¤„ç†æµ‹è¯•æˆåŠŸ: {result['details']}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "details": "é”™è¯¯å¤„ç†æµ‹è¯•æ—¶å‘ç”Ÿå¼‚å¸¸"
            }

    def save_test_results(self, results: Dict[str, Any], output_file: str = None):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if output_file is None:
            output_file = f"tests/results/ai_integration_test_{int(time.time())}.json"

        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            Path(output_file).parent.mkdir(parents=True, exist_ok=True)

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)

            self.logger.info(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

        except Exception as e:
            self.logger.error(f"ä¿å­˜æµ‹è¯•ç»“æœå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›¡ï¸ SSlogs AIé›†æˆåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)

    tester = AIIntegrationTester()
    results = tester.run_all_tests()

    # ä¿å­˜æµ‹è¯•ç»“æœ
    tester.save_test_results(results)

    # æ˜¾ç¤ºæµ‹è¯•æ‘˜è¦
    print("\nğŸ“Š æµ‹è¯•æ‘˜è¦:")
    print(f"æ€»æµ‹è¯•æ•°: {results['total_tests']}")
    print(f"é€šè¿‡æµ‹è¯•: {results['passed_tests']}")
    print(f"å¤±è´¥æµ‹è¯•: {results['failed_tests']}")
    print(f"æˆåŠŸç‡: {results['success_rate']:.1f}%")

    if results['failed_tests'] > 0:
        print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test_name, result in results['test_results'].items():
            if not result.get('success', False):
                print(f"  - {test_name}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°æµ‹è¯•æ–‡ä»¶")

    return results['success_rate']

if __name__ == "__main__":
    success_rate = main()
    sys.exit(0 if success_rate >= 80 else 1)