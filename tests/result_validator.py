#!/usr/bin/env python3
"""
SSlogs æµ‹è¯•ç»“æœéªŒè¯å™¨
éªŒè¯æµ‹è¯•ç»“æœçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Set
from datetime import datetime

class ResultValidator:
    """æµ‹è¯•ç»“æœéªŒè¯å™¨"""

    def __init__(self, results_dir: str = "tests/results"):
        self.results_dir = Path(results_dir)
        self.logger = self._setup_logging()

        # é¢„æœŸç»“æœæ˜ å°„
        self.expected_matches = {
            'ai_ml_anomaly': ['AI/MLé©±åŠ¨çš„å¼‚å¸¸è¡Œä¸ºæ£€æµ‹'],
            'threat_intelligence': ['å¨èƒæƒ…æŠ¥è‡ªåŠ¨æ£€æµ‹ä¸IOCåŒ¹é…'],
            'zero_trust': ['é›¶ä¿¡ä»»æ¶æ„å®‰å…¨æ£€æµ‹'],
            'supply_chain': ['è½¯ä»¶ä¾›åº”é“¾å®‰å…¨å¨èƒæ£€æµ‹'],
            'cloud_native': ['äº‘åŸç”Ÿé«˜çº§å¨èƒæ£€æµ‹'],
            'privacy_compliance': ['éšç§åˆè§„æ€§æ£€æµ‹è§„åˆ™'],
            'financial_security': ['é‡‘èè¡Œä¸šå®‰å…¨å¨èƒæ£€æµ‹'],
            'user_behavior': ['ç”¨æˆ·å®ä½“è¡Œä¸ºåˆ†æ(UEBA)æ£€æµ‹'],
            'attack_chain': ['æ”»å‡»é“¾å…³è”æ£€æµ‹è§„åˆ™'],
            'automated_response': ['è‡ªåŠ¨åŒ–å“åº”è§¦å‘è§„åˆ™']
        }

        # éªŒè¯ç»“æœ
        self.validation_results = {
            'total_categories': 0,
            'validated_categories': 0,
            'failed_validations': [],
            'validation_details': {}
        }

    def _setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)

    def load_latest_results(self) -> Dict[str, Any]:
        """åŠ è½½æœ€æ–°çš„æµ‹è¯•ç»“æœ"""
        result_files = list(self.results_dir.glob("test_results_*.json"))
        if not result_files:
            raise FileNotFoundError("æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•ç»“æœæ–‡ä»¶")

        latest_file = max(result_files, key=lambda x: x.stat().st_mtime)
        self.logger.info(f"åŠ è½½æµ‹è¯•ç»“æœ: {latest_file}")

        with open(latest_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def validate_rule_coverage(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯è§„åˆ™è¦†ç›–ç‡"""
        self.logger.info("å¼€å§‹éªŒè¯è§„åˆ™è¦†ç›–ç‡...")

        coverage_results = {}

        for category, category_results in results.items():
            self.logger.info(f"éªŒè¯ç±»åˆ«: {category}")

            # ç»Ÿè®¡åŒ¹é…åˆ°çš„è§„åˆ™
            matched_rules = set()
            total_tests = len(category_results)

            for result in category_results:
                if result.get('success', False) and 'matched_rules' in result:
                    matched_rules.update(result['matched_rules'])

            # è®¡ç®—è¦†ç›–ç‡
            expected_rules = set(self.expected_matches.get(category, []))
            coverage_rate = len(matched_rules) / len(expected_rules) if expected_rules else 0

            coverage_results[category] = {
                'total_tests': total_tests,
                'successful_tests': sum(1 for r in category_results if r.get('success', False)),
                'matched_rules': list(matched_rules),
                'expected_rules': list(expected_rules),
                'coverage_rate': coverage_rate,
                'is_fully_covered': matched_rules >= expected_rules
            }

            self.logger.info(f"  æµ‹è¯•æ•°: {total_tests}, æˆåŠŸ: {coverage_results[category]['successful_tests']}")
            self.logger.info(f"  è§„åˆ™è¦†ç›–ç‡: {coverage_rate:.2%}")

        return coverage_results

    def validate_threat_scoring(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å¨èƒè¯„åˆ†"""
        self.logger.info("å¼€å§‹éªŒè¯å¨èƒè¯„åˆ†...")

        scoring_results = {}

        for category, category_results in results.items():
            scores = []
            high_score_tests = 0

            for result in category_results:
                if result.get('success', False) and 'threat_scores' in result:
                    scores.extend(result['threat_scores'])
                    if any(score >= 7.0 for score in result['threat_scores']):
                        high_score_tests += 1

            # è®¡ç®—è¯„åˆ†ç»Ÿè®¡
            if scores:
                avg_score = sum(scores) / len(scores)
                max_score = max(scores)
                min_score = min(scores)
            else:
                avg_score = max_score = min_score = 0

            scoring_results[category] = {
                'total_scores': len(scores),
                'average_score': avg_score,
                'max_score': max_score,
                'min_score': min_score,
                'high_score_tests': high_score_tests,
                'scoring_effective': avg_score >= 5.0  # å¹³å‡åˆ†åº”è¯¥è¶…è¿‡5.0
            }

            self.logger.info(f"  å¹³å‡å¨èƒè¯„åˆ†: {avg_score:.2f}, æœ€é«˜: {max_score:.2f}")

        return scoring_results

    def validate_false_positives(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯è¯¯æŠ¥æƒ…å†µ"""
        self.logger.info("å¼€å§‹éªŒè¯è¯¯æŠ¥æƒ…å†µ...")

        false_positive_results = {}

        for category, category_results in results.items():
            successful_tests = 0
            false_positive_tests = 0

            for result in category_results:
                if result.get('success', False):
                    successful_tests += 1
                    # æ£€æŸ¥æ˜¯å¦ä¸ºåˆç†çš„å¨èƒè¯„åˆ†
                    if 'threat_scores' in result:
                        if any(score < 3.0 for score in result['threat_scores']):
                            false_positive_tests += 1

            false_positive_rate = false_positive_tests / successful_tests if successful_tests > 0 else 0

            false_positive_results[category] = {
                'successful_tests': successful_tests,
                'false_positive_tests': false_positive_tests,
                'false_positive_rate': false_positive_rate,
                'acceptable': false_positive_rate <= 0.2  # è¯¯æŠ¥ç‡åº”è¯¥ä½äº20%
            }

            self.logger.info(f"  è¯¯æŠ¥ç‡: {false_positive_rate:.2%}")

        return false_positive_results

    def validate_attack_patterns(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯æ”»å‡»æ¨¡å¼æ£€æµ‹"""
        self.logger.info("å¼€å§‹éªŒè¯æ”»å‡»æ¨¡å¼æ£€æµ‹...")

        pattern_results = {}

        # å®šä¹‰é¢„æœŸçš„æ”»å‡»æ¨¡å¼
        expected_patterns = {
            'ai_ml_anomaly': ['å¼‚å¸¸è¡Œä¸ºæ”»å‡»', 'ç»•è¿‡è¡Œä¸ºæ£€æµ‹'],
            'threat_intelligence': ['æ¶æ„è½¯ä»¶ä¼ æ’­', 'C2é€šä¿¡'],
            'zero_trust': ['èº«ä»½éªŒè¯ç»•è¿‡', 'æƒé™æå‡'],
            'supply_chain': ['ä¾èµ–æ··æ·†æ”»å‡»', 'CI/CDç®¡é“æ”»å‡»'],
            'cloud_native': ['å®¹å™¨é€ƒé€¸æ”»å‡»', 'Kubernetesæƒé™æå‡'],
            'privacy_compliance': ['éšç§æ•°æ®æ³„éœ²', 'åŒæ„ç®¡ç†ç»•è¿‡'],
            'financial_security': ['æ”¯ä»˜ç³»ç»Ÿæ”»å‡»', 'é‡‘èæ•°æ®æ³„éœ²'],
            'user_behavior': ['å†…éƒ¨å¨èƒ', 'è´¦æˆ·åŠ«æŒ'],
            'attack_chain': ['å¤šé˜¶æ®µæ”»å‡»', 'APTæ”»å‡»'],
            'automated_response': ['è‡ªåŠ¨åŒ–æ”»å‡»', 'å¤§è§„æ¨¡æ”»å‡»']
        }

        for category, category_results in results.items():
            detected_patterns = set()

            for result in category_results:
                if result.get('success', False) and 'matched_rules' in result:
                    # è¿™é‡Œå¯ä»¥æ ¹æ®è§„åˆ™åç§°æ¨æ–­æ”»å‡»æ¨¡å¼
                    for rule_name in result['matched_rules']:
                        if 'å¼‚å¸¸' in rule_name:
                            detected_patterns.add('å¼‚å¸¸è¡Œä¸ºæ”»å‡»')
                        if 'ç»•è¿‡' in rule_name:
                            detected_patterns.add('ç»•è¿‡è¡Œä¸ºæ£€æµ‹')
                        if 'æ¶æ„' in rule_name:
                            detected_patterns.add('æ¶æ„è½¯ä»¶ä¼ æ’­')
                        if 'C2' in rule_name or 'æ§åˆ¶' in rule_name:
                            detected_patterns.add('C2é€šä¿¡')
                        if 'èº«ä»½' in rule_name:
                            detected_patterns.add('èº«ä»½éªŒè¯ç»•è¿‡')
                        if 'æƒé™' in rule_name:
                            detected_patterns.add('æƒé™æå‡')
                        if 'å®¹å™¨' in rule_name:
                            detected_patterns.add('å®¹å™¨é€ƒé€¸æ”»å‡»')
                        if 'éšç§' in rule_name:
                            detected_patterns.add('éšç§æ•°æ®æ³„éœ²')
                        if 'æ”¯ä»˜' in rule_name:
                            detected_patterns.add('æ”¯ä»˜ç³»ç»Ÿæ”»å‡»')
                        if 'åŠ«æŒ' in rule_name:
                            detected_patterns.add('è´¦æˆ·åŠ«æŒ')
                        if 'å¤šé˜¶æ®µ' in rule_name or 'APT' in rule_name:
                            detected_patterns.add('APTæ”»å‡»')

            expected = set(expected_patterns.get(category, []))
            pattern_coverage = len(detected_patterns & expected) / len(expected) if expected else 0

            pattern_results[category] = {
                'detected_patterns': list(detected_patterns),
                'expected_patterns': list(expected),
                'pattern_coverage': pattern_coverage,
                'patterns_detected': len(detected_patterns & expected),
                'total_expected_patterns': len(expected)
            }

            self.logger.info(f"  æ”»å‡»æ¨¡å¼è¦†ç›–ç‡: {pattern_coverage:.2%}")

        return pattern_results

    def validate_performance(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯æ€§èƒ½æŒ‡æ ‡"""
        self.logger.info("å¼€å§‹éªŒè¯æ€§èƒ½æŒ‡æ ‡...")

        performance_results = {}

        for category, category_results in results.items():
            successful_tests = sum(1 for r in category_results if r.get('success', False))
            total_tests = len(category_results)

            success_rate = successful_tests / total_tests if total_tests > 0 else 0

            performance_results[category] = {
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'success_rate': success_rate,
                'performance_acceptable': success_rate >= 0.8  # æˆåŠŸç‡åº”è¯¥è¶…è¿‡80%
            }

            self.logger.info(f"  æˆåŠŸç‡: {success_rate:.2%}")

        return performance_results

    def run_full_validation(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´éªŒè¯"""
        self.logger.info("å¼€å§‹å®Œæ•´éªŒè¯æµç¨‹...")

        validation_results = {
            'validation_timestamp': datetime.now().isoformat(),
            'rule_coverage': self.validate_rule_coverage(results),
            'threat_scoring': self.validate_threat_scoring(results),
            'false_positives': self.validate_false_positives(results),
            'attack_patterns': self.validate_attack_patterns(results),
            'performance': self.validate_performance(results)
        }

        # è®¡ç®—æ€»ä½“è¯„åˆ†
        overall_score = self._calculate_overall_score(validation_results)
        validation_results['overall_score'] = overall_score
        validation_results['validation_passed'] = overall_score >= 80.0

        return validation_results

    def _calculate_overall_score(self, validation_results: Dict[str, Any]) -> float:
        """è®¡ç®—æ€»ä½“è¯„åˆ†"""
        scores = []

        # è§„åˆ™è¦†ç›–ç‡è¯„åˆ† (30%)
        coverage_rates = [v['coverage_rate'] for v in validation_results['rule_coverage'].values()]
        if coverage_rates:
            scores.append(sum(coverage_rates) / len(coverage_rates) * 30)

        # å¨èƒè¯„åˆ†æœ‰æ•ˆæ€§ (20%)
        scoring_effectiveness = sum(1 for v in validation_results['threat_scoring'].values() if v['scoring_effective'])
        total_categories = len(validation_results['threat_scoring'])
        if total_categories > 0:
            scores.append((scoring_effectiveness / total_categories) * 20)

        # è¯¯æŠ¥ç‡è¯„åˆ† (20%)
        acceptable_false_positives = sum(1 for v in validation_results['false_positives'].values() if v['acceptable'])
        if total_categories > 0:
            scores.append((acceptable_false_positives / total_categories) * 20)

        # æ€§èƒ½è¯„åˆ† (30%)
        success_rates = [v['success_rate'] for v in validation_results['performance'].values()]
        if success_rates:
            scores.append(sum(success_rates) / len(success_rates) * 30)

        return sum(scores)

    def save_validation_report(self, validation_results: Dict[str, Any]) -> str:
        """ä¿å­˜éªŒè¯æŠ¥å‘Š"""
        report_file = self.results_dir / f"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(validation_results, f, indent=2, ensure_ascii=False)

        self.logger.info(f"éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return str(report_file)

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='SSlogs æµ‹è¯•ç»“æœéªŒè¯å™¨')
    parser.add_argument('--results-dir', default='tests/results', help='æµ‹è¯•ç»“æœç›®å½•')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')

    args = parser.parse_args()

    try:
        validator = ResultValidator(args.results_dir)

        # åŠ è½½æµ‹è¯•ç»“æœ
        results = validator.load_latest_results()

        # è¿è¡ŒéªŒè¯
        validation_results = validator.run_full_validation(results)

        # ä¿å­˜éªŒè¯æŠ¥å‘Š
        report_file = validator.save_validation_report(validation_results)

        # è¾“å‡ºéªŒè¯ç»“æœ
        print(f"ğŸ“Š éªŒè¯å®Œæˆï¼æ€»ä½“è¯„åˆ†: {validation_results['overall_score']:.1f}/100")
        print(f"âœ… éªŒè¯çŠ¶æ€: {'é€šè¿‡' if validation_results['validation_passed'] else 'æœªé€šè¿‡'}")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")

        if args.verbose:
            print("\nğŸ“‹ è¯¦ç»†éªŒè¯ç»“æœ:")
            for category in results.keys():
                print(f"\nğŸ”¸ {category}:")
                print(f"  è§„åˆ™è¦†ç›–ç‡: {validation_results['rule_coverage'][category]['coverage_rate']:.2%}")
                print(f"  å¹³å‡å¨èƒè¯„åˆ†: {validation_results['threat_scoring'][category]['average_score']:.2f}")
                print(f"  è¯¯æŠ¥ç‡: {validation_results['false_positives'][category]['false_positive_rate']:.2%}")
                print(f"  æˆåŠŸç‡: {validation_results['performance'][category]['success_rate']:.2%}")

        return 0 if validation_results['validation_passed'] else 1

    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    import sys
    sys.exit(main())