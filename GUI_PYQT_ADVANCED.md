# PyQt6 GUI新功能说明

## AI模型选择功能

PyQt6 GUI界面现在支持两种AI分析模式：

### 1. 云端SiliconFlow模型
- **特点**: 使用云端AI服务进行分析，无需本地部署
- **配置要求**: 需要有效的API密钥和模型名称
- **使用场景**: 网络连接稳定，需要高质量AI分析的环境

### 2. 本地Ollama模型
- **特点**: 使用本地AI模型进行分析，离线可用
- **配置要求**: 需要运行中的Ollama服务和模型名称
- **使用场景**: 网络不稳定或需要离线分析的环境

## 使用步骤

### 1. 启动GUI界面
```bash
python launcher.py --gui
```

### 2. 配置AI模型

在"AI配置"选项卡中：
1. **选择AI模型类型**:
   - "云端 (SiliconFlow)" 或 "本地 (Ollama)"
2. **输入模型名称**:
   - 云端: `deepseek-ai/DeepSeek-V3` (默认)
   - 本地: `deepseek-r1:14b` (默认)
3. **输入API密钥** (仅云端模式):
   - 填写您的SiliconFlow API密钥

### 3. 测试AI连接
点击"测试AI连接"按钮验证配置是否正确。

### 4. 开始分析
- 填写其他必要信息（日志目录、主机IP等）
- 点击"开始分析"按钮

## 注意事项

### 云端AI配置
- API密钥必须正确填写才能使用
- 确保网络连接稳定以获得最佳性能
- 超时时间默认为30秒，可根据需要调整

### 本地AI配置
- 确保Ollama服务正在运行（默认端口11434）
- 模型必须已下载到Ollama服务中
- 超时时间默认为60秒

## 故障排除

### AI连接失败
1. 检查网络连接是否正常
2. 验证API密钥或Ollama服务状态
3. 确认模型名称是否正确
4. 尝试使用"测试AI连接"按钮进行诊断

### 性能问题
- 如果云端AI响应缓慢，考虑增加超时时间
- 本地AI分析可能需要更多系统资源